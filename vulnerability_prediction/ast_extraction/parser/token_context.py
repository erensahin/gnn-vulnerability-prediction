""" Token context module to manage token-id matching """

import os
import pickle
import pandas as pd
from vulnerability_prediction import AST_OUTPUT_DIR
from vulnerability_prediction.utils import LOGGER

VOCAB_DF_PATH = os.path.join(AST_OUTPUT_DIR, "vocab.csv")
VOCAB_PKL_PATH = os.path.join(AST_OUTPUT_DIR, "vocab.pkl")


class TokenContext():
    """ Token Manager """

    def __init__(self):
        self._vocab = self._read_vocab()

    @classmethod
    def _read_vocab(cls):
        with open(VOCAB_PKL_PATH, "rb") as f:
            vocab = pickle.load(f)

        LOGGER.info("Read vocabulary.. size: %d", len(vocab))

        return vocab

    def _export_vocab(self):
        with open(VOCAB_PKL_PATH, "wb") as f:
            pickle.dump(self._vocab, f)

        tokens_df = pd.DataFrame.from_dict(self._vocab, orient="index")
        tokens_df.columns = ["id"]
        tokens_df.to_csv(os.path.join(AST_OUTPUT_DIR, "vocab.csv"),
                         index_label="token")

    def _update_vocab(self, token):
        self._vocab[token] = max(self._vocab.values()) + 1

    def get_token_ids(self, tokens):
        """
        Return token - id matching of given tokens
        Update vocabulary if a token is not in vocab and give it an id.

        :param list[string] tokens:
            List of tokens
        :returns list
            List of token ids
        """
        updated = False
        token_ids = []

        for tok in tokens:
            if tok not in self._vocab:
                self._update_vocab(tok)
                updated = True

            token_ids.append(self._vocab[tok])

        if updated:
            self._export_vocab()

        return token_ids
