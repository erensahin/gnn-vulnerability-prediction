""" TF-IDF training over tokens of the tree """

import os
import pickle
import ast
import zipfile

import pandas as pd
import numpy as np

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.svm import LinearSVC, SVC
from sklearn.metrics import confusion_matrix, precision_recall_fscore_support
from sklearn.calibration import CalibratedClassifierCV

from vulnerability_prediction import REPOS, AST_OUTPUT_DIR
from vulnerability_prediction.utils import LOGGER

AST_DIR = REPOS["wireshark"]["ast_output_dir"]


def get_vocab():
    """Read the dict of vocabulary"""
    with open(os.path.join(AST_OUTPUT_DIR, "vocab.pkl"), "rb") as f:
        vocab = pickle.load(f)

    return {v: k for k, v in vocab.items()}


def get_trees():
    """ Read preprocessed trees """
    with zipfile.ZipFile(os.path.join(AST_DIR, "trees_2020-02-13.zip")) as myzip:
        with myzip.open("trees.pkl", "r") as f:
            trees = pickle.load(f)

    for tree in trees:
        func_decl_node = tree["df"].iloc[0]
        extent_end = ast.literal_eval(func_decl_node.extent_end)
        extent_start = ast.literal_eval(func_decl_node.extent_start)
        tree["loc"] = extent_end[0] - extent_start[0]
        tree["n_tokens"] = len(ast.literal_eval(func_decl_node.tokens))
    return trees


def get_tokens(tree, vocab):
    """ Convert token ids to source code tokens """
    for token in ast.literal_eval(tree.tokens.values[0]):
        try:
            yield vocab[token]
        except:
            continue


def get_input(trees, vocab):
    """Converts trees to a generator pair of tokens and labels"""
    for tree in trees:
        tokens = " ".join([str(t) for t in get_tokens(tree["df"], vocab)])
        yield (tokens, tree["label"])


def get_train_test_data(trees, vocab):
    """Gets input data and splits it to a train and test data"""

    n_nodes_limit = 49.20 + 3 * 206.84
    n_loc_limit = 137.23 + 3 * 764.48
    n_token_limit = 741.19 + 3 * 4059.165812

    n_nodes_low_limit = 9 / 2
    n_loc_low_limit = 6 / 2
    n_token_low_limit = 51 / 2

    trees_ = [
        {**t} for t in trees if t["label"] == 1 or 
        (t["label"] == 0 and 
         len(t["df"]) < n_nodes_limit and len(t["df"]) >= n_nodes_low_limit and
         t["loc"] < n_loc_limit and t["loc"] >= n_loc_low_limit and
         t["n_tokens"] < n_token_limit and t["n_tokens"] >= n_token_low_limit)
    ]

    input_data = list(get_input(trees_, vocab))
    x, y = map(list, zip(*input_data))

    x_train, x_test, y_train, y_test = train_test_split(
        x, y, test_size=0.20, random_state=1773, stratify=y
    )

    return x_train, x_test, y_train, y_test


def tf_idf_vectorizer(train_set, test_set):
    """TF-IDF vectorization over training and test data"""
    vectorizer = CountVectorizer(max_features=1000)
    x_train = vectorizer.fit_transform(train_set)
    x_test = vectorizer.transform(test_set)

    return x_train, x_test


def classification_report(preds):
    """Evaluates predictions and generates a report for classification
    Args:
        preds: DataFrame of predictions having actual and predicted values
    """
    acc = preds.loc[preds.actual == preds.pred].shape[0] / preds.shape[0]

    clf_results = np.array(
        precision_recall_fscore_support(preds["actual"],
                                        preds["pred"]))

    results_by_class = pd.DataFrame(clf_results.T,
                                    columns=['precision', 'recall',
                                             'f1-score', 'support'],
                                    index=[0, 1]
                                    )

    avg_precision = np.sum(clf_results[0] * clf_results[3]) / np.sum(
        clf_results[3])
    avg_recall = np.sum(clf_results[1] * clf_results[3]) / np.sum(
        clf_results[3])
    f1_score = np.sum(clf_results[2] * clf_results[3]) / np.sum(
        clf_results[3])

    scores = {
        'acc': round(acc, 3),
        'avg_precision': round(avg_precision, 3),
        'avg_recall': round(avg_recall, 3),
        'f1_score': round(f1_score, 3)
    }

    conf_matrix = pd.DataFrame(
        confusion_matrix(preds["actual"], preds["pred"]),
        columns=[0, 1],
        index=[0, 1])

    print('Confusion Matrix: \n')
    print(conf_matrix)
    print('\nPrecision, Recall, F1-Scores for Classes\n')
    print(results_by_class)
    print('\nScores\n')
    print(scores)

    return preds, scores, results_by_class, conf_matrix


def main():
    """
    Main training & testing process
    """
    LOGGER.info("started..")

    trees = get_trees()
    vocab = get_vocab()

    LOGGER.info("read trees and vocabulary")

    x_train, x_test, y_train, y_test = get_train_test_data(trees, vocab)
    x_train, x_test = tf_idf_vectorizer(x_train, x_test)

    LOGGER.info("Train - test data is obtained")

    import ipdb
    ipdb.set_trace()
    svm = LinearSVC(loss="squared_hinge", dual=False)
    svm = svm.fit(x_train, y_train)
    model = CalibratedClassifierCV(svm, cv="prefit")

    pred = model.predict(x_test)
    probs = model.predict_proba(x_test)

    LOGGER.info("model is trained")

    results_df = pd.DataFrame(zip(y_test, pred), columns=["actual", "pred"])
    _, scores, results_by_class, conf_matrix = classification_report(
        results_df)

    print(results_by_class)

    results_df.to_csv("token_based_results.csv")


if __name__ == "__main__":
    main()
